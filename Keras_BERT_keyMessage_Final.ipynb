{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install pandas\n",
    "# !pip3 install numpy\n",
    "# !pip3 install Keras\n",
    "# !pip3 install keras-bert\n",
    "# !pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Keras\n",
    "#!pip install keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"keyMssg_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Over 10 00 patients have been treated with XAL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Female , 65 years of age Theresa is not an act...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Discontinue ELIQUIS and begin taking the new a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>- 3 + t Examples of locations of injury includ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Alphagan Brimonidine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Over 10 00 patients have been treated with XAL...      0\n",
       "1  Female , 65 years of age Theresa is not an act...      8\n",
       "2  Discontinue ELIQUIS and begin taking the new a...      3\n",
       "3  - 3 + t Examples of locations of injury includ...     13\n",
       "4                               Alphagan Brimonidine      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     * An attempt should be made to locate missing ...\n",
       "Label                                                    8\n",
       "Name: 16, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60\n",
    "BATCH_SIZE = 18\n",
    "EPOCHS = 3\n",
    "LR = 4e-5\n",
    "\n",
    "pretrained_path = '../BERT_BioBERT/Text_semantic/model_folder/'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "\n",
    "DATA_COLUMN = 'Text'\n",
    "LABEL_COLUMN = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'config_path': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls config_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = load_vocabulary(vocab_path)\n",
    "tokenizer = Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Convert to data that BERT understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data_df):\n",
    "    global tokenizer\n",
    "    indices, targets = [], []\n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
    "        indices.append(ids)\n",
    "        targets.append(data_df[LABEL_COLUMN][i])\n",
    "    items = list(zip(indices, targets))\n",
    "    np.random.shuffle(items)\n",
    "    indices, targets = zip(*items)\n",
    "    indices = np.array(indices)\n",
    "    return [indices, np.zeros_like(indices)], np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_df):\n",
    "    #data_df = pd.read_csv(path, nrows=10000)\n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    data_x, data_y = convert_data(data_df)\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13031/13031 [00:09<00:00, 1446.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = load_data(data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0109 09:36:11.071736 139821173102400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0109 09:36:11.091523 139821173102400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0109 09:36:11.142937 139821173102400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0109 09:36:11.144199 139821173102400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0109 09:36:11.152195 139821173102400 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0109 09:36:11.185086 139821173102400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    training=True,\n",
    "    trainable=True,\n",
    "    seq_len=SEQ_LEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Keras Model and compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 09:36:32.531810 139821173102400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = model.inputs[:2]\n",
    "dense = model.layers[-3].output\n",
    "outputs = keras.layers.Dense(16, activation='softmax', kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "                             name = 'real_output')(dense)\n",
    "\n",
    "decay_steps, warmup_steps = calc_train_steps(\n",
    "    train_y.shape[0],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    AdamWarmup(decay_steps=decay_steps, warmup_steps=warmup_steps, lr=LR),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 60, 768), (3 23440896    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 60, 768)      1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 60, 768)      0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 60, 768)      46080       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 60, 768)      0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 60, 768)      1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 60, 768)      2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 60, 768)      0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 60, 768)      2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 60, 768)      0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 60, 768)      1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 60, 768)      4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 60, 768)      0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 60, 768)      0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 60, 768)      1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 60, 768)      2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 60, 768)      0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 60, 768)      0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 60, 768)      1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 60, 768)      4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 60, 768)      0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 60, 768)      0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 60, 768)      1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 60, 768)      2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 60, 768)      0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 60, 768)      0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 60, 768)      1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 60, 768)      4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 60, 768)      0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 60, 768)      0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 60, 768)      1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 60, 768)      2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 60, 768)      0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 60, 768)      0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 60, 768)      1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 60, 768)      4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 60, 768)      0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 60, 768)      0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 60, 768)      1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "real_output (Dense)             (None, 16)           12304       NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,147,408\n",
      "Trainable params: 109,147,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 09:36:32.728948 139821173102400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10424 samples, validate on 2607 samples\n",
      "Epoch 1/3\n",
      "10424/10424 [==============================] - 359s 34ms/step - loss: 1.3850 - acc: 0.6089 - val_loss: 0.8362 - val_acc: 0.7603\n",
      "Epoch 2/3\n",
      "10424/10424 [==============================] - 343s 33ms/step - loss: 0.6251 - acc: 0.8291 - val_loss: 0.7443 - val_acc: 0.7944\n",
      "Epoch 3/3\n",
      "10424/10424 [==============================] - 343s 33ms/step - loss: 0.3562 - acc: 0.9064 - val_loss: 0.7468 - val_acc: 0.7979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f29fff35710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model.save('model_finalized_v1_81_71.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model.save_weights('my_awesome_model') # save it\n",
    "# model = load_model('my_awesome_model', encoder_model) # load it later and use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction script for test file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Prediction Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import get_custom_objects\n",
    "import keras\n",
    "import time\n",
    "\n",
    "SEQ_LEN = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model one time\n",
    "def loadModel_vocab(path = \"/home/ajeetsingh/Documents/VCC/keyMessage/BERT\"):\n",
    "    vocab_path = path+'/vocab_uncased_81_71.txt'\n",
    "    token_dict = load_vocabulary(vocab_path)\n",
    "    tokenizer = Tokenizer(token_dict)\n",
    "    \n",
    "    model = keras.models.load_model(path +'/model_finalized_v1_81_71.h5', custom_objects=get_custom_objects())\n",
    "    return model, tokenizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get prediction from loaded model\n",
    "def getPredictionFromBERT(text, model, tokenizer):\n",
    "    \n",
    "    ids, segments = tokenizer.encode(input_text, max_len=SEQ_LEN)\n",
    "    model_input = [np.array([ids]), np.zeros_like([ids])]\n",
    "    prediction = model1.predict(model_input)\n",
    "    \n",
    "    return prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 08:48:40.697624 140524488652608 deprecation_wrapper.py:119] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 08:48:40.734422 140524488652608 deprecation_wrapper.py:119] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0826 08:48:40.802501 140524488652608 deprecation_wrapper.py:119] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 08:48:40.803157 140524488652608 deprecation_wrapper.py:119] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0826 08:48:40.810594 140524488652608 deprecation.py:506] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0826 08:48:40.861757 140524488652608 deprecation_wrapper.py:119] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0826 08:48:47.575183 140524488652608 deprecation_wrapper.py:119] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0826 08:48:47.705020 140524488652608 deprecation.py:323] From /home/ajeetsingh/Documents/VCC/keyMessage/keyMessageBERT/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 28.512789011001587 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#main function to load and get final prediction\n",
    "start_time = time.time()\n",
    "model1, tokenizer1 = loadModel_vocab()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"For patients who remain symptomatic on a short acting bronchodilator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5454251e-04 2.7663815e-03 2.8993129e-03 1.5515804e-02 6.6051739e-03\n",
      "  6.3632051e-03 8.8909721e-01 1.9974783e-03 4.3881793e-02 1.1408570e-03\n",
      "  1.2701717e-03 1.8673387e-03 1.6779760e-02 8.8643614e-04 6.7116898e-03\n",
      "  1.9628755e-03]]\n",
      "--- 0.13864898681640625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(getPredictionFromBERT(input_text, model1, tokenizer1))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction testing for batch of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import get_custom_objects\n",
    "import keras as keras\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEQ_LEN = 60\n",
    "\n",
    "DATA_COLUMN = 'Text'\n",
    "\n",
    "def convert_test(test_df, tokenizer):\n",
    "    #global tokenizer\n",
    "    indices = []\n",
    "    for i in range(len(test_df)):\n",
    "        ids, segments = tokenizer.encode(test_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
    "        indices.append(ids)\n",
    "    indices = np.array(indices)\n",
    "    return [indices, np.zeros_like(indices)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getPredictionFromBERTForBatchOfRecords(df,model, tokenizer):\n",
    "    text_x = convert_test(df, tokenizer1)\n",
    "    result = model.predict(test_x)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and get prediction\n",
    "def load_test(path):\n",
    "    data_df = pd.read_csv(path, nrows=100)\n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    #data_x = convert_test(data_df)\n",
    "    return data_df\n",
    "\n",
    "test_x = load_test('/home/ajeetsingh/Documents/VCC/keyMessage/BioBert/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# print(getPredictionFromBERTForBatchOfRecords(test_x, model1, tokenizer1))\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Script for a batch of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/merk_RTE_slices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/RTE_slices_35.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2212, 86)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1501, 86)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([data, data1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3599, 87)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3599"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3713-114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/Merck_RTE_Slices_Indication.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3599, 87)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    data['text'][i] = str(data['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>slice_link</th>\n",
       "      <th>slide_link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>FORXIGAⓇy XIGDUO® XR: the most prescribed iSGL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>LESS GLUCOSE. MORE RESULTS.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>Significant reductions in HbA1c 2 * Decrease o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>ONCE A xigduo day. XR dapagliflozin + extended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>http://c-cube-dev.indegene.com:8080/static/get...</td>\n",
       "      <td>See the local product feature summary (CPR) fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         slice_link  \\\n",
       "0      0  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "1      1  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "2      2  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "3      3  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "4      4  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "\n",
       "                                          slide_link  \\\n",
       "0  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "1  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "2  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "3  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "4  http://c-cube-dev.indegene.com:8080/static/get...   \n",
       "\n",
       "                                                text  \n",
       "0  FORXIGAⓇy XIGDUO® XR: the most prescribed iSGL...  \n",
       "1                        LESS GLUCOSE. MORE RESULTS.  \n",
       "2  Significant reductions in HbA1c 2 * Decrease o...  \n",
       "3  ONCE A xigduo day. XR dapagliflozin + extended...  \n",
       "4  See the local product feature summary (CPR) fo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import get_custom_objects\n",
    "import keras as keras\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "SEQ_LEN = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0116 17:14:47.711898 139746573064000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0116 17:14:47.733593 139746573064000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0116 17:14:47.768815 139746573064000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0116 17:14:47.769380 139746573064000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0116 17:14:47.774981 139746573064000 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0116 17:14:47.795558 139746573064000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loading....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0116 17:14:52.390303 139746573064000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0116 17:14:52.482115 139746573064000 deprecation.py:323] From /home/ajeeth/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20.43277072906494 seconds ---\n",
      "Model Loaded!!\n",
      "Input file is loading\n",
      "Input file loaded\n",
      "--- 166.29082012176514 seconds ---\n",
      "Getting Prediction\n"
     ]
    }
   ],
   "source": [
    "# /home/ajeeth/Documents/VCC/gitVCC/vcc-models/Ajeet_4616/KeyMessage_BERT_81_2/model\n",
    "\n",
    "DATA_COLUMN = 'text'\n",
    "vocab_path = '../model/keyMessage_vocab_uncased_81_71.txt'\n",
    "\n",
    "token_dict = load_vocabulary(vocab_path)\n",
    "tokenizer1 = Tokenizer(token_dict)\n",
    "\n",
    "print(\"Model Loading....\")\n",
    "start_time = time.time()\n",
    "loaded_model = keras.models.load_model('../model/keyMessage_model_finalized_v1_81_71.h5', custom_objects=get_custom_objects())\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"Model Loaded!!\")\n",
    "\n",
    "print(\"Input file is loading\")\n",
    "\n",
    "def convert_test(test_df, tokenizer):\n",
    "    #global tokenizer\n",
    "    indices = []\n",
    "    for i in range(len(test_df)):\n",
    "        ids, segments = tokenizer.encode(test_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
    "        indices.append(ids)\n",
    "    indices = np.array(indices)\n",
    "    return [indices, np.zeros_like(indices)]\n",
    "\n",
    "def load_test(path):\n",
    "    data_df = pd.read_csv(path)\n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    data_x = convert_test(data_df, tokenizer1)\n",
    "    return data_x\n",
    "\n",
    "\n",
    "test_x = load_test('/home/ajeeth/Documents/VCC/keyMessage/Indication_model/Merck_RTE_Slices_Indication.csv')\n",
    "\n",
    "print(\"Input file loaded\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = loaded_model.predict(test_x)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print(\"Saving into Numpy\")\n",
    "\n",
    "# np.save('spanish_numpy_array', result) \n",
    "\n",
    "#Get the index of the max prob values\n",
    "\n",
    "print(\"Getting Prediction\")\n",
    "preds = []\n",
    "for prediction in result:\n",
    "    preds.append(np.argmax(prediction))\n",
    "\n",
    "#key message category list\n",
    "le_classes = ['Brand Information',\n",
    "'Comparative Information',\n",
    "'Cost',\n",
    "'Disease Management',\n",
    "'Dosing & Administration',\n",
    "'Efficacy',\n",
    "'Indication',\n",
    "'Pathology',\n",
    "'Patient Profile',\n",
    "'Pharmacology',\n",
    "'Physician Enablement',\n",
    "'Risk Factor',\n",
    "'Safety & Tolerability',\n",
    "'Study Design',\n",
    "'Summary',\n",
    "'Unmet Need']\n",
    "\n",
    "#get the key message category name from the index\n",
    "pred_class = []\n",
    "\n",
    "for i in preds:\n",
    "    pred_class.append(le_classes[i])\n",
    "\n",
    "\n",
    "#append the prediction with the original dataframe\n",
    "test_x = pd.read_csv('/home/ajeeth/Documents/VCC/keyMessage/Indication_model/Merck_RTE_Slices_Indication.csv')\n",
    "test_x['Prediction_iDA_BERT_KeyMessage'] = pred_class\n",
    "\n",
    "# #save the data file\n",
    "\n",
    "# test_x.to_csv(\"Spanish_5200_BERT_Prediction.csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Prediction Completed\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>S. No.</th>\n",
       "      <th>Asset Name</th>\n",
       "      <th>Asset Type</th>\n",
       "      <th>Slide Name</th>\n",
       "      <th>deckid</th>\n",
       "      <th>slideid</th>\n",
       "      <th>_id</th>\n",
       "      <th>Modified Asset ID</th>\n",
       "      <th>Modified Slide ID</th>\n",
       "      <th>...</th>\n",
       "      <th>messagecategories.Resources</th>\n",
       "      <th>messagecategories.Risk Markers</th>\n",
       "      <th>messagecategories.Safety &amp; Tolerability</th>\n",
       "      <th>messagecategories.Summary</th>\n",
       "      <th>messagecategories.Trial Design</th>\n",
       "      <th>messagecategories.Unmet Needs</th>\n",
       "      <th>corrected.mediatype</th>\n",
       "      <th>corrected.messagecategories</th>\n",
       "      <th>corrected.semantictype</th>\n",
       "      <th>Prediction_iDA_BERT_KeyMessage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ObjectId(5daec67f6640611af0f00197)</td>\n",
       "      <td>ObjectId(5daec6816640611af0f00198)</td>\n",
       "      <td>ObjectId(5daec6a06640611af0f00199)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>{\"Valid Mailbox\":1.0}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>Physician Enablement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ObjectId(5daec67f6640611af0f00197)</td>\n",
       "      <td>ObjectId(5daec6816640611af0f00198)</td>\n",
       "      <td>ObjectId(5daec6a26640611af0f0019a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"NA\":1.0}</td>\n",
       "      <td>{}</td>\n",
       "      <td>Patient Profile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  S. No.  Asset Name  Asset Type  Slide Name  \\\n",
       "0      0     NaN         NaN         NaN         NaN   \n",
       "1      1     NaN         NaN         NaN         NaN   \n",
       "\n",
       "                               deckid                             slideid  \\\n",
       "0  ObjectId(5daec67f6640611af0f00197)  ObjectId(5daec6816640611af0f00198)   \n",
       "1  ObjectId(5daec67f6640611af0f00197)  ObjectId(5daec6816640611af0f00198)   \n",
       "\n",
       "                                  _id  Modified Asset ID  Modified Slide ID  \\\n",
       "0  ObjectId(5daec6a06640611af0f00199)                NaN                NaN   \n",
       "1  ObjectId(5daec6a26640611af0f0019a)                NaN                NaN   \n",
       "\n",
       "   ...  messagecategories.Resources  messagecategories.Risk Markers  \\\n",
       "0  ...                       0.1075                             NaN   \n",
       "1  ...                       0.0096                             NaN   \n",
       "\n",
       "   messagecategories.Safety & Tolerability  messagecategories.Summary  \\\n",
       "0                                   0.0173                     0.0041   \n",
       "1                                   0.0144                     0.0035   \n",
       "\n",
       "   messagecategories.Trial Design  messagecategories.Unmet Needs  \\\n",
       "0                             NaN                         0.0046   \n",
       "1                             NaN                         0.0053   \n",
       "\n",
       "     corrected.mediatype corrected.messagecategories corrected.semantictype  \\\n",
       "0  {\"Valid Mailbox\":1.0}                          {}                     {}   \n",
       "1                     {}                  {\"NA\":1.0}                     {}   \n",
       "\n",
       "  Prediction_iDA_BERT_KeyMessage  \n",
       "0           Physician Enablement  \n",
       "1                Patient Profile  \n",
       "\n",
       "[2 rows x 88 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://c-cube-dev.indegene.com/asset/\"\n",
    "test_x['deckid'] = test_x.deckid.str.replace('ObjectId','')\n",
    "test_x['deckid'] = test_x.deckid.str.replace('(','')\n",
    "test_x['deckid'] = test_x.deckid.str.replace(')','')\n",
    "\n",
    "test_x['_id'] = test_x[\"_id\"].str.replace('ObjectId','')\n",
    "test_x['_id'] = test_x[\"_id\"].str.replace('(','')\n",
    "test_x['_id'] = test_x[\"_id\"].str.replace(')','')\n",
    "\n",
    "test_x[\"slice_link\"]= base_url + test_x[\"deckid\"] +\"/slices/\" + test_x[\"_id\"] +\".png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.to_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/Merck_RTE_Slices_Indication_predicted_BERT.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Prediction_BERT</th>\n",
       "      <th>Prediction_BERT_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, Label, Prediction_BERT, Prediction_BERT_test]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[test_x['Prediction_BERT'] != test_x['Prediction_BERT_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_class = []\n",
    "\n",
    "for i in test_x['Label']:\n",
    "#     print(le_classes[i])\n",
    "    actual_class.append(le_classes[i])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x['Actual_class'] = actual_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "      Brand Information       0.93      0.95      0.94       129\n",
      "Comparative Information       0.88      0.44      0.58        16\n",
      "                   Cost       0.94      0.93      0.94       127\n",
      "     Disease Management       0.86      0.91      0.89       170\n",
      "Dosing & Administration       0.93      0.95      0.94       288\n",
      "               Efficacy       0.91      0.92      0.91       412\n",
      "             Indication       0.92      0.94      0.93       128\n",
      "              Pathology       0.81      0.86      0.83       134\n",
      "        Patient Profile       0.96      0.87      0.91       179\n",
      "           Pharmacology       0.95      0.93      0.94       167\n",
      "   Physician Enablement       0.97      0.97      0.97       234\n",
      "            Risk Factor       0.61      0.69      0.65        16\n",
      "  Safety & Tolerability       0.95      0.96      0.96       805\n",
      "           Study Design       0.91      0.94      0.92       420\n",
      "                Summary       0.00      0.00      0.00        16\n",
      "             Unmet Need       1.00      0.35      0.52        17\n",
      "\n",
      "               accuracy                           0.92      3258\n",
      "              macro avg       0.85      0.79      0.80      3258\n",
      "           weighted avg       0.92      0.92      0.92      3258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_x['Actual_class'], test_x['Prediction_BERT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merk_id = [\"5db9922666406147260e211e\",\"5dc2942d66406165645cf4a8\",\"5dc2a1266640610638b02c90\",\"5dc2a1406640610638b02ca4\",\"5db97c1866406147260e202f\",\"5dc25c9e66406165645cf31c\",\"5dc25cc466406165645cf31e\",\"5dc25cf966406165645cf32d\",\"5dc25d1366406165645cf33d\",\"5dc3f02866406111e5c388bf\",\"5dbffa1d66406147260e2b15\",\"5dc3b16d66406111e5c38879\",\"5dc3f01066406111e5c388bd\",\"5dc27d8166406165645cf438\",\"5dc2976366406165645cf4f3\",\"5dc2977a66406165645cf4f5\",\"5dc2a08d6640610638b02c7d\",\"5dc2a09f6640610638b02c7f\",\"5dc2a0b06640610638b02c81\",\"5dc2a0c36640610638b02c84\",\"5dbabb0c66406147260e28bf\",\"5dc27d1c66406165645cf436\",\"5dc1230666406147260e2b6a\",\"5dbae29d66406147260e2945\",\"5dbfd66166406147260e2a25\",\"5dbfd58866406147260e29ea\",\"5db96b6e66406147260e1f53\",\"5dbfcd0b66406147260e299a\",\"5db97c9366406147260e2070\",\"5db97c5366406147260e2047\",\"5dc25d3766406165645cf362\",\"5db9916466406147260e2106\",\"5daf37f66640611af0f004c6\",\"5daec67f6640611af0f00197\",\"5db9905b66406147260e20c9\",\"5dc25d6266406165645cf38f\",\"5dc2c08666406111e5c38803\",\"5dbfd15b66406147260e29c1\",\"5db97be566406147260e201e\",\"5db990e666406147260e20e4\",\"5dc3ba5066406111e5c388ac\",\"5dc3ba7966406111e5c388b3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_id = [\"5d11cf7a3f6c5432268f7ae4\",\"5d11cebc3f6c5432268f7a8b\",\"5d11ce583f6c5432268f7a58\",\"5d11cdbd3f6c5432268f79ff\",\"5d11cd9e3f6c5432268f79e6\",\"5d11e1f83f6c5432268f7bca\",\"5d11e1493f6c5432268f7ba7\",\"5d11e04f3f6c5432268f7b79\",\"5d11dfb63f6c5432268f7b55\",\"5d11df293f6c5432268f7b2e\",\"5d11e2cf3f6c5432268f7bfa\",\"5d11e35d3f6c5432268f7c2c\",\"5d11e3e33f6c5432268f7c5b\",\"5d11e7683f6c5432268f7cab\",\"5d22dd893f6c54102196c807\",\"5d22de2b3f6c54102196c823\",\"5d22de9a3f6c54102196c861\",\"5d22df0e3f6c54102196c891\",\"5d22df8f3f6c54102196c906\",\"5d22edbf3f6c54102196ca9e\",\"5d22ede03f6c54102196caac\",\"5d22ee6e3f6c54102196cae7\",\"5d22ef323f6c54102196cb9d\",\"5d22efa83f6c54102196cc3e\",\"5d2318673f6c54102196cca0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_merk = pd.read_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/med_comp/slides_merk_rte.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_35 = pd.read_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/med_comp/slides_merk_35.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rte = pd.read_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/med_comp/Merck_RTE_Slices_Indication_predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ObjectId(5d11cd9e3f6c5432268f79e6)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_35['deckid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5daf37f66640611af0f004c6'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rte['deckid'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_35['deckid'] = slide_35[\"deckid\"].str.replace('ObjectId','')\n",
    "slide_35['deckid'] = slide_35[\"deckid\"].str.replace('(','')\n",
    "slide_35['deckid'] = slide_35[\"deckid\"].str.replace(')','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_merk['deckid'] = slide_merk[\"deckid\"].str.replace('ObjectId','')\n",
    "slide_merk['deckid'] = slide_merk[\"deckid\"].str.replace('(','')\n",
    "slide_merk['deckid'] = slide_merk[\"deckid\"].str.replace(')','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_35 = dict(zip(slide_35['deckid'], slide_35['filename']))\n",
    "slide_merk = dict(zip(slide_merk['deckid'], slide_merk['filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5daec67f6640611af0f00197'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_merk['deckid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://icb-merck.indegene.com/asset/5db97c1866406147260e202f/HEDIS_HQ_Email_1.png'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url_merk = \"https://icb-merck.indegene.com/asset/\"\n",
    "base_url_dev = \"http://c-cube-dev.indegene.com/asset/\"\n",
    "base_url_merk+data_rte[\"deckid\"][10]+\"/\"+slide_merk[data_rte['deckid'][10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_link_list = []\n",
    "base_url_merk = \"https://icb-merck.indegene.com/asset/\"\n",
    "base_url_dev = \"http://c-cube-dev.indegene.com/asset/\"\n",
    "\n",
    "for i in range(data_rte.shape[0]):\n",
    "    if(data_rte['deckid'][i] in merk_id):\n",
    "        slide_link_list.append(base_url_merk+data_rte[\"deckid\"][i]+\"/\"+slide_merk[data_rte['deckid'][i]])\n",
    "    elif(data_rte['deckid'][i] in dev_id):\n",
    "        slide_link_list.append(base_url_dev+data_rte[\"deckid\"][i]+\"/\"+mapping_35[data_rte['deckid'][i]])\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rte['slide_link'] = slide_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://c-cube-dev.indegene.com/asset/5d11ce583f6c5432268f7a58/Chinese_3_2.png'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rte['slide_link'][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rte.to_csv(\"/home/ajeeth/Documents/VCC/keyMessage/Indication_model/med_comp/Merck_RTE_Slices_Indication_predicted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
